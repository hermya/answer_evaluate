{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I travel from home to school\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\Heramb/.cache\\torch\\sentence_transformers\\sbert.net_models_bert-base-nli-mean-tokens\\0_BERT were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 768)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9829394]], dtype=float32)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(\n",
    "    [my_sentence_embeddings[0]],\n",
    "    sentence_embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_sentence = [\"I travel from school to home\"]\n",
    "my_sentence_embeddings = model.encode(my_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Heramb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from to transition to be worked on\n",
    "# or transition to be worked on\n",
    "# adjective transition\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('It', 'PRP'), ('was', 'VBD'), ('the', 'DT'), ('same', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "sentence = \"It was the same\"\n",
    "x = nltk.pos_tag(word_tokenize(sentence))\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in x:\n",
    "    d[i[1]]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x:\n",
    "    d[i[1]].append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NN': ['transfer', 'pollen', 'anther', 'stigma', 'flower'],\n",
       " 'NNS': ['grains'],\n",
       " 'IN': ['from', 'of'],\n",
       " 'DT': ['the', 'the', 'the'],\n",
       " 'TO': ['to'],\n",
       " 'JJ': ['same'],\n",
       " '.': ['.']}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark and John are sincere employees at Google.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nnoun_adj_pairs = []\\nfor i,token in enumerate(doc):\\n    if token.pos_ not in ('NOUN','PROPN'):\\n        continue\\n    for j in range(i+1,len(doc)):\\n        if doc[j].pos_ == 'ADJ':\\n            noun_adj_pairs.append((token,doc[j]))\\n            break\\nnoun_adj_pairs\\n\""
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u'Mark and John are sincere employees at Google.')\n",
    "print()\n",
    "\"\"\"\n",
    "noun_adj_pairs = []\n",
    "for i,token in enumerate(doc):\n",
    "    if token.pos_ not in ('NOUN','PROPN'):\n",
    "        continue\n",
    "    for j in range(i+1,len(doc)):\n",
    "        if doc[j].pos_ == 'ADJ':\n",
    "            noun_adj_pairs.append((token,doc[j]))\n",
    "            break\n",
    "noun_adj_pairs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I ,  I ,  PRON ,  PRP ,  nsubj ,  X ,  True ,  True\n",
      "travel ,  travel ,  VERB ,  VBP ,  ROOT ,  xxxx ,  True ,  False\n",
      "from ,  from ,  ADP ,  IN ,  prep ,  xxxx ,  True ,  True\n",
      "or ,  or ,  CCONJ ,  CC ,  cc ,  xx ,  True ,  True\n",
      "home ,  home ,  NOUN ,  NN ,  conj ,  xxxx ,  True ,  False\n",
      "to ,  to ,  ADP ,  IN ,  prep ,  xx ,  True ,  True\n",
      "school ,  school ,  NOUN ,  NN ,  pobj ,  xxxx ,  True ,  False\n",
      ". ,  . ,  PUNCT ,  . ,  punct ,  . ,  False ,  False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"I travel from or home to school.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,\", \", token.lemma_,\", \", token.pos_,\", \", token.tag_,\", \", token.dep_,\", \",\n",
    "            token.shape_,\", \", token.is_alpha,\", \", token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(flowers, different)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'It occurs in the flowers which are genetically different.')\n",
    "noun_adj_pairs = []\n",
    "for i,token in enumerate(doc):\n",
    "    if token.pos_ not in ('NOUN','PROPN'):\n",
    "        continue\n",
    "    for j in range(i+1,len(doc)):\n",
    "        if doc[j].pos_ == 'ADJ':\n",
    "            noun_adj_pairs.append((token,doc[j]))\n",
    "            break\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"Self-Pollination\" : \"This process can take place in the same flower or a different flower of the same plant.\",\n",
    "       \"Cross-Pollination\" : \"This process can take place between two flowers present on different plants.\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk =  It\n",
      "chunk =  the flowers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flowers': []}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('It occurs in the flowers which are genetically identical.')\n",
    "\n",
    "noun_adj_pairs = {}\n",
    "for chunk in doc.noun_chunks:\n",
    "    adj = []\n",
    "    noun = \"\"\n",
    "    for tok in chunk:\n",
    "        if tok.pos_ == \"NOUN\":\n",
    "            noun = tok.text\n",
    "        if tok.pos_ == \"ADJ\":\n",
    "            adj.append(tok.text)\n",
    "    if noun:\n",
    "        if noun not in noun_adj_pairs.keys():\n",
    "            noun_adj_pairs[noun] = []\n",
    "        noun_adj_pairs[noun] += adj\n",
    "    print(\"chunk = \",chunk)\n",
    "\n",
    "# expected output\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple is looking at buying U.K. startup for $1 billion\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.K.\n",
      "startup\n",
      "for\n",
      "$\n",
      "1\n",
      "billion\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk =  It\n",
      "chunk =  the flowers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flowers': []}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "doc = nlp('It occurs in the flowers which are genetically identical.')\n",
    "\n",
    "noun_adj_pairs = {}\n",
    "for chunk in doc.noun_chunks:\n",
    "    adj = []\n",
    "    noun = \"\"\n",
    "    for tok in chunk:\n",
    "        if tok.pos_ == \"NOUN\":\n",
    "            noun = tok.text\n",
    "        if tok.pos_ == \"ADV\":\n",
    "            adj.append(tok.text)\n",
    "    if noun:\n",
    "        if noun not in noun_adj_pairs.keys():\n",
    "            noun_adj_pairs[noun] = []\n",
    "        noun_adj_pairs[noun] += adj\n",
    "    print(\"chunk = \",chunk)\n",
    "\n",
    "# expected output\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(flowers, identical)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'It occurs in the flowers which are genetically identical.')\n",
    "noun_adj_pairs = []\n",
    "for i,token in enumerate(doc):\n",
    "    if token.pos_ not in ('NOUN','PROPN'):\n",
    "        continue\n",
    "    for j in range(i+1,len(doc)):\n",
    "        if doc[j].pos_ == 'ADJ':\n",
    "            noun_adj_pairs.append((token,doc[j]))\n",
    "            break\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'direct object'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glossary.explain('dobj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk =  a different flower\n",
      "chunk =  the same plant\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'flower': ['different'], 'plant': ['same']}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "#nlp = spacy.load('en_core_web_sm')\n",
    "#doc = nlp('I travel from home to school')\n",
    "doc = nlp(' '.join([ a.text for a in ls[1]]))\n",
    "#doc.get_lca_matrix()\n",
    "noun_adj_pairs = {}\n",
    "for chunk in doc.noun_chunks:\n",
    "    adj = []\n",
    "    noun = \"\"\n",
    "    for tok in chunk:\n",
    "        if tok.pos_ == \"NOUN\":\n",
    "            noun = tok.text\n",
    "        if tok.pos_ == \"ADJ\":\n",
    "            adj.append(tok.text)\n",
    "    if noun:\n",
    "        if noun not in noun_adj_pairs.keys():\n",
    "            noun_adj_pairs[noun] = []\n",
    "        noun_adj_pairs[noun] += adj\n",
    "    print(\"chunk = \",chunk)\n",
    "\n",
    "# expected output\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 2, 2, 2, 2],\n",
       "       [1, 1, 2, 3, 2, 2],\n",
       "       [1, 1, 2, 2, 4, 4],\n",
       "       [1, 1, 2, 2, 4, 5]])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.get_lca_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(from, home), (to, school)]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(u'I travel from home using a taxi to school using a bus')\n",
    "noun_adj_pairs = []\n",
    "for i,token in enumerate(doc):\n",
    "    if token.pos_ in ('ADP'):\n",
    "        for j in range(i+1,len(doc)):\n",
    "            if doc[j].pos_ in ('NOUN','PROPN','PRON'):\n",
    "                noun_adj_pairs.append((token,doc[j]))\n",
    "                break\n",
    "noun_adj_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'reverse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-197-94f4905d3e05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'reverse'"
     ]
    }
   ],
   "source": [
    "'It happens in a manner A or it doesn\\'t happen at all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Syntactical dependancy</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Is alpha?</th>\n",
       "      <th>Is stop-word?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "      <td>determiner</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process</td>\n",
       "      <td>process</td>\n",
       "      <td>noun</td>\n",
       "      <td>NN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can</td>\n",
       "      <td>can</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>MD</td>\n",
       "      <td>aux</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take</td>\n",
       "      <td>take</td>\n",
       "      <td>verb</td>\n",
       "      <td>VB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>place</td>\n",
       "      <td>place</td>\n",
       "      <td>noun</td>\n",
       "      <td>NN</td>\n",
       "      <td>dobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>between</td>\n",
       "      <td>between</td>\n",
       "      <td>adposition</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flowers</td>\n",
       "      <td>flower</td>\n",
       "      <td>noun</td>\n",
       "      <td>NNS</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>adposition</td>\n",
       "      <td>IN</td>\n",
       "      <td>prep</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>determiner</td>\n",
       "      <td>DT</td>\n",
       "      <td>det</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>different</td>\n",
       "      <td>different</td>\n",
       "      <td>adjective</td>\n",
       "      <td>JJ</td>\n",
       "      <td>amod</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>plants</td>\n",
       "      <td>plant</td>\n",
       "      <td>noun</td>\n",
       "      <td>NNS</td>\n",
       "      <td>pobj</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Text      Lemma         POS  Tag Syntactical dependancy Shape  \\\n",
       "0        This       this  determiner   DT                    det  Xxxx   \n",
       "1     process    process        noun   NN                  nsubj  xxxx   \n",
       "2         can        can   auxiliary   MD                    aux   xxx   \n",
       "3        take       take        verb   VB                   ROOT  xxxx   \n",
       "4       place      place        noun   NN                   dobj  xxxx   \n",
       "5     between    between  adposition   IN                   prep  xxxx   \n",
       "6     flowers     flower        noun  NNS                   pobj  xxxx   \n",
       "7          of         of  adposition   IN                   prep    xx   \n",
       "8         the        the  determiner   DT                    det   xxx   \n",
       "9   different  different   adjective   JJ                   amod  xxxx   \n",
       "10     plants      plant        noun  NNS                   pobj  xxxx   \n",
       "\n",
       "    Is alpha?  Is stop-word?  \n",
       "0        True           True  \n",
       "1        True          False  \n",
       "2        True           True  \n",
       "3        True           True  \n",
       "4        True          False  \n",
       "5        True           True  \n",
       "6        True          False  \n",
       "7        True           True  \n",
       "8        True           True  \n",
       "9        True          False  \n",
       "10       True          False  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.glossary import explain\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(u\"This process can take place between flowers of the different plants\")\n",
    "data = []\n",
    "for token in doc:\n",
    "    data.append([token.text, token.lemma_, explain(token.pos_), token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Text\",\"Lemma\",\"POS\",\"Tag\",\"Syntactical dependancy\",\"Shape\",\"Is alpha?\",\"Is stop-word?\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [[],[]]\n",
    "cconj  = False\n",
    "for token in doc:\n",
    "    if token.pos_ == 'CCONJ':\n",
    "        cconj = True\n",
    "    elif not cconj:\n",
    "        ls[0].append(token)\n",
    "    else:\n",
    "        ls[1].append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[This, process, can, take, place, in, the, same, flower],\n",
       " [a, different, flower, of, the, same, plant]]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This, process, can, take, place, in, the, same, flower]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"This process can take place between flowers of the different plants\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Lemma</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Syntactical dependancy</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Is alpha?</th>\n",
       "      <th>Is stop-word?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This</td>\n",
       "      <td>this</td>\n",
       "      <td>determiner</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "      <td>Xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>process</td>\n",
       "      <td>process</td>\n",
       "      <td>noun</td>\n",
       "      <td>NN</td>\n",
       "      <td>nominal subject</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can</td>\n",
       "      <td>can</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>MD</td>\n",
       "      <td>auxiliary</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take</td>\n",
       "      <td>take</td>\n",
       "      <td>verb</td>\n",
       "      <td>VB</td>\n",
       "      <td>None</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>place</td>\n",
       "      <td>place</td>\n",
       "      <td>noun</td>\n",
       "      <td>NN</td>\n",
       "      <td>direct object</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>between</td>\n",
       "      <td>between</td>\n",
       "      <td>adposition</td>\n",
       "      <td>IN</td>\n",
       "      <td>prepositional modifier</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flowers</td>\n",
       "      <td>flower</td>\n",
       "      <td>noun</td>\n",
       "      <td>NNS</td>\n",
       "      <td>object of preposition</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>adposition</td>\n",
       "      <td>IN</td>\n",
       "      <td>prepositional modifier</td>\n",
       "      <td>xx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>determiner</td>\n",
       "      <td>DT</td>\n",
       "      <td>determiner</td>\n",
       "      <td>xxx</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>different</td>\n",
       "      <td>different</td>\n",
       "      <td>adjective</td>\n",
       "      <td>JJ</td>\n",
       "      <td>adjectival modifier</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>plants</td>\n",
       "      <td>plant</td>\n",
       "      <td>noun</td>\n",
       "      <td>NNS</td>\n",
       "      <td>object of preposition</td>\n",
       "      <td>xxxx</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Text      Lemma         POS  Tag  Syntactical dependancy Shape  \\\n",
       "0        This       this  determiner   DT              determiner  Xxxx   \n",
       "1     process    process        noun   NN         nominal subject  xxxx   \n",
       "2         can        can   auxiliary   MD               auxiliary   xxx   \n",
       "3        take       take        verb   VB                    None  xxxx   \n",
       "4       place      place        noun   NN           direct object  xxxx   \n",
       "5     between    between  adposition   IN  prepositional modifier  xxxx   \n",
       "6     flowers     flower        noun  NNS   object of preposition  xxxx   \n",
       "7          of         of  adposition   IN  prepositional modifier    xx   \n",
       "8         the        the  determiner   DT              determiner   xxx   \n",
       "9   different  different   adjective   JJ     adjectival modifier  xxxx   \n",
       "10     plants      plant        noun  NNS   object of preposition  xxxx   \n",
       "\n",
       "    Is alpha?  Is stop-word?  \n",
       "0        True           True  \n",
       "1        True          False  \n",
       "2        True           True  \n",
       "3        True           True  \n",
       "4        True          False  \n",
       "5        True           True  \n",
       "6        True          False  \n",
       "7        True           True  \n",
       "8        True           True  \n",
       "9        True          False  \n",
       "10       True          False  "
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy.glossary import explain\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(x)\n",
    "data = []\n",
    "for token in doc:\n",
    "    data.append([token.text, token.lemma_, explain(token.pos_), token.tag_, explain(token.dep_),token.shape_, token.is_alpha, token.is_stop])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"Text\",\"Lemma\",\"POS\",\"Tag\",\"Syntactical dependancy\",\"Shape\",\"Is alpha?\",\"Is stop-word?\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take\n",
      "Text => This process \t& root =>  process \t& root type =>  nsubj \t& ==  take\n",
      "take\n",
      "Text => place \t& root =>  place \t& root type =>  dobj \t& ==  take\n",
      "between\n",
      "Text => flowers \t& root =>  flowers \t& root type =>  pobj \t& ==  between\n",
      "of\n",
      "Text => the different plants \t& root =>  plants \t& root type =>  pobj \t& ==  of\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(\"Text =>\",chunk.text, \"\\t& root => \",chunk.root.text, \"\\t& root type => \",chunk.root.dep_,\"\\t& == \",\n",
    "            chunk.root.head.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mitochondria is the cell of the powerhouse'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Mitochondria is the powerhouse of cell\"\n",
    "\n",
    "\"Mitochondria is the not the powerhouse of cell\"# 87.5%\n",
    "\"Cell is the powerhouse of mitochondria\" \n",
    "\"Mitochondria is the powerhouse of plant cell\"\n",
    "\"Mitochondria is the cell of the powerhouse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adjectival modifier'"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "chu = list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.span.Span' object has no attribute '__dict__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-284-5d059a3dd34d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mchu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'spacy.tokens.span.Span' object has no attribute '__dict__'"
     ]
    }
   ],
   "source": [
    "chu[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
